{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e8efcc4",
   "metadata": {},
   "source": [
    "### 1. Cite 5 diferenças entre o RandomForest e o AdaBoost:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b47999",
   "metadata": {},
   "source": [
    "- 1.\tNo Adaboost as árvores(stumps) tem pesos diferentes baseados na qualidade da resposta, diferente do RF em que todas as árvores tem o mesmo peso; \n",
    "\n",
    "- 2.\tAdaboost tem menor probabilidade de overfitting em relação ao RF devido à característica do item 1;\n",
    "- 3.\tAdaboost constrói um modelo final baseado em um conjunto de modelos ‘fracos’, em que os modelos são dependentes e tem uma ordem de criação, onde o objetivo do modelo seguinte é corrigir os erros do modelo anterior (boosting). Diferente do RF em que o modelo final é baseado em vários subconjuntos de dados criados de forma aleatória (bagging);\n",
    "- 4.\tAdaboost utiliza árvores de 1 profundidade e 2 folhas, enquanto RF utiliza árvores completas;\n",
    "- 5.\tAdaboost é mais eficaz para conjuntos de dados pequenos e desequilibrados, porém é menos robusto a ruídos e outliers. Já o RF é mais robusto a ruídos e outliers, porém tem menor precisão para conjuntos de dados grandes e equilibrados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c263beaa",
   "metadata": {},
   "source": [
    "### 2.Acesse o link Scikit-learn–adaboost, leia a explicação (traduza se for preciso) e crie um jupyternotebook contendo o exemplo do AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652b1d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f11872",
   "metadata": {},
   "source": [
    "### 3. Cite 5 Hyperparametros importantes no AdaBoost:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df3581",
   "metadata": {},
   "source": [
    "- 1.\tn_estimators: número de stumps que serão treinados; \n",
    "- 2.\tlearning_rate: peso dado a cada stump. Tem por padrão o valor 1 mas pode ser ajustado para otimizar o modelo;\n",
    "- 3.\testimator: tipo de modelo de aprendizado que será utilizado. Tem por padrão o stump, mas podem ser utilizados outros modelos, como por exemplo árvores de decisão ou regras de associação;\n",
    "- 4.\talgorithm: pode ser SAMME ou SAMME.R. O primeiro define o uso de um algoritmo real de boosting. Já o segundo usa um algoritmo de boosting discreto;\n",
    "- 5.\trandom_state: define o número do qual se deseja adquirir o mesmo resultado sempre que rodar o código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a1d68",
   "metadata": {},
   "source": [
    "### 4. (Opcional) Utilize o GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb90b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ba94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "70 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 124, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'learning_rate' parameter of AdaBoostClassifier must be a float in the range (0, inf). Got 0 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 124, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of AdaBoostClassifier must be an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alext\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667        nan 0.93333333\n",
      " 0.94       0.94666667 0.94666667        nan 0.95333333 0.95333333\n",
      " 0.89333333 0.89333333        nan 0.94666667 0.94666667 0.94666667\n",
      " 0.94666667        nan 0.94666667 0.94666667 0.94666667 0.94666667\n",
      "        nan 0.94666667 0.94666667 0.94666667 0.94666667        nan\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667        nan 0.94666667\n",
      " 0.94666667 0.94666667 0.94666667        nan 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 3, 'n_estimators': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'n_estimators': list(range(0, 50, 10)),\n",
    "    'learning_rate': list(range(0, 10, 1))\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator = clf,\n",
    "                    param_grid = parameters,\n",
    "                    scoring = 'accuracy',\n",
    "                    cv = 5)\n",
    "\n",
    "grid.fit(X, y)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc71a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
